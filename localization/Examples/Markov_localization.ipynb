{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the material explained in the lesson about Markov Localization, an essential technique for achieving precise localization in autonomous vehicles (AVs). As AVs navigate through complex environments, accurate and reliable localization is as crucial as a driver knowing their exact location on the road.\n",
    "\n",
    "### The Need for Accurate Localization\n",
    "\n",
    "Autonomous vehicles rely on accurate localization to navigate safely and efficiently. Incorrect localization can lead to navigation errors, compromising the safety of the vehicle and its surroundings. Thus, ensuring the vehicle knows its exact position and orientation relative to a map is foundational for autonomous driving technologies.\n",
    "\n",
    "### Challenges in Localization\n",
    "\n",
    "Effective localization faces several challenges:\n",
    "\n",
    "- **Dynamic Environments:** The environment around a vehicle is constantly changing. Moving objects like pedestrians and other vehicles, along with varying weather conditions, can affect sensor reliability and accuracy.\n",
    "\n",
    "- **GPS Limitations:** While GPS provides valuable location data, its reliability can decrease significantly in urban areas with tall buildings (known as urban canyons) or in regions where satellite signals are obstructed.\n",
    "\n",
    "### Overcoming the challenges\n",
    "\n",
    "Markov Localization offers a robust solution to these challenges. This method integrates sensor data and pre-existing map information to estimate the most probable vehicle location under uncertain conditions. By continuously updating its state with incoming sensor data, Markov Localization helps maintain accurate positioning even when GPS data is unreliable or unavailable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understaing Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To formalize the localization problem we will rely on the following notations:\n",
    "\n",
    "- $m$: Represents the digital map, which could be a grid map, a feature map, or a map of landmarks.\n",
    "\n",
    "- $\\mathbf{z}_{t:1}$: Represents A sequence of observations from time $1$ to $t$, possibly including range measurements, bearings, or images. For instance, with a radar sensor in a 1D map, we obtain the distance $x$ to landmarks; in a 2D map, distances $x, y$ are obtained. \n",
    "    $$\n",
    "        \\mathbf{z}_{t:1} = [\\mathbf{z}_t, ...,\\mathbf{z}_i, .... , \\mathbf{z}_1] \\\\\n",
    "        \\mathbf{z}_i =  [z_i^1, ..., z_i^k]\n",
    "    $$\n",
    "\n",
    "    Where $z_i$ is the observation vector at time $i$, and $z_i^k$ is the $k^{th}$ observation of $z_i$\n",
    "\n",
    "- $\\mathbf{u}_{t:1}$: Represents the control vector containing control inputs from time $1$ to $t$:\n",
    "\n",
    "    $$\n",
    "        \\mathbf{u}_{t:1} = [u_t, .... u_1]\n",
    "    $$\n",
    "\n",
    "- $\\mathbf{x}_t$: Represents the state vector representing the vehicle's pose (position and orientation) at time $t$:\n",
    "\n",
    "    $$\n",
    "        \\mathbf{x}_t = [x_t,y_t,\\theta_t]\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given a map $m$, observation sequence $z_{t:1}$ and a control vector $\\mathbf{u}_{t:1}$, the localization problem is to determine the probability or belief $bel(\\mathbf{x}_t)$ of the vehicle being in a particular state $\\mathbf{x}_t$:\n",
    "\n",
    "$$\n",
    "    bel(\\mathbf{x}_t) = P(\\mathbf{x}_t | \\mathbf{z}_{t:1}, \\mathbf{u}_{t:1}, m)\n",
    "$$\n",
    "\n",
    "This probability is represented as a vector in a 1D map or a matrix in a 2D map, illustrating the vehicle's possible locations across the map dimensions, as follows:\n",
    "\n",
    "- **1D representation:**\n",
    "    $$\n",
    "        bel(\\mathbf{x}_t) = [bel(x_t=0), bel(x_t=1), ..., bel(x_t=M)]\n",
    "    $$\n",
    "\n",
    "- **2D Case:**\n",
    "    $$\n",
    "        bel(\\mathbf{x}_t) = \\begin{bmatrix}\n",
    "                                bel(x_t=0, y_t=0) & \\cdots & bel(x_t=M, y_t=0) \\\\\n",
    "                                    \\vdots & \\ddots & \\vdots \\\\\n",
    "                                bel(x_t=0, y_t=N) & \\cdots & bel(x_t=M, y_t=N) \\\\\n",
    "                                \n",
    "                            \\end{bmatrix}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To assess the aformention problem, Markov Localization relies on the Bayes' rule. This is a fundamental theorem in probability theory that allows us to update our beliefs based on new evidence. It is central to numerous applications in statistical inference, and in the context of localization for autonomous vehicles, it plays a pivotal role in updating the belief state of a vehicle regarding its position.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "Bayes' rule can be mathematically formulated as follows:\n",
    "\n",
    "$$\n",
    "    P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $P(A | B)$ is the probability of event $A$ given that event $B$ has occurred.\n",
    "- $P(B | A)$ is the probability of observing event $B$ given that event $A$ is true.\n",
    "- $P(A)$ is the prior probability of event $A$ happening.\n",
    "- $P(B)$ is the total probability of observing event $B$.\n",
    "\n",
    "In the localization scenario:\n",
    "\n",
    "- $A$ represents the hypothesis about the vehicle’s location.\n",
    "- $B$ represents the observation data from sensors.\n",
    "\n",
    "This way Bayes' rule can be reinterpreted as follows:\n",
    "\n",
    "$$\n",
    "    P(\\text{location}|\\text{observation}) = \\frac{P(\\text{observation}|\\text{location}) \\times P(\\text{location})}{P(\\text{observation})}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $P(\\text{location}|\\text{observation})$ is the normalized probability of a position given an observation.\n",
    "- $P(\\text{observation}|\\text{location})$ is the probability of an observation given a position (likelihood).\n",
    "- $P(\\text{location})$ is the **prior** probability of a position.\n",
    "- $P(\\text{observation})$ is the total probability of an observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective localization in autonomous vehicles is essential for accurate navigation, especially in dynamic environments where precision is crucial for safety and operational efficiency. \n",
    "\n",
    "Let's consider that our observations come from a lidar, that this lidar has sample rate of 10 Hz and that we have recorded for 8 hours. How much data is stored in $\\mathbf{z}_{t:1}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tools.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pcd = utils.pcd_from_path(\"./dataset/example_velodyne.pcd\")\n",
    "pointcloud_size = sys.getsizeof(pcd) # Bytes/frame\n",
    "sample_rate = 10 # frame/second\n",
    "hours = 8 # Hours\n",
    "\n",
    "# Calculate total size\n",
    "total_size = hours*3600*sample_rate*pointcloud_size\n",
    "\n",
    "print(f\"Total data to process {total_size} Bytes\")\n",
    "print(f\"Total data to process {total_size/(1024**3)} Giga Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, as more time we have adquiring data, we continue accumlating data on our system which can lead to exploding sizes of data and computational time to process each frame. For localization we need to satisfy the following requirements.\n",
    "\n",
    "1. Less amount of data possible\n",
    "2. Amount of data remains constant\n",
    "\n",
    "To make this possible, we need to find a solution that satisfies the above requirements. The idea is to manipulate the **posterior** $$bel(\\mathbf{x}_t)$$ in a way that we can get a recursive state estimator, so we just use the previous beliefs $$bel(\\mathbf{x}_{t-1})$$ and current observation $\\mathbf{z}_t$ to calculate current beliefs, this means:\n",
    "\n",
    "$$\n",
    "    bel(\\mathbf{x}_t) = f(bel(\\mathbf{x}_{t-1}, \\mathbf{z}_t))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Applying Bayes Rule to the Localization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To effectively utilize Bayes' Rule in updating our belief states for localization, we start by refining how we structure our observations. Specifically, we decompose the sequence of observations, into two parts: the most recent observation $z_t$​ and all prior observations $z_{t−1:1}$​. This allows us to reformulate our belief expression as:\n",
    "\n",
    "$$\n",
    "    bel(\\mathbf{x}_t) = P(\\mathbf{x}_t | \\mathbf{z}_{t:1}, \\mathbf{u}_{t:1}, m) = P(\\mathbf{x}_t |  \\mathbf{z}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)\n",
    "$$\n",
    "\n",
    "Given that the current state is $x_t$ and the most recent observation is $z_t$​, we can update our belief about the vehicle's location using Bayes' Rule as follows:\n",
    "$$\n",
    "     bel(\\mathbf{x}_t) = \n",
    "     P(\\mathbf{x}_t |  \\mathbf{z}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = \n",
    "     \\frac{P(\\mathbf{z}_t |  \\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) \\times P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)}\n",
    "          {P(\\mathbf{z}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "\n",
    "- $P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)$ is the **Prior** or the **Motion Model** or the **Transition Model**\n",
    "- $P(\\mathbf{z}_t |  \\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)$ is the **likelihood** or the **Observation Model**. (We asume $\\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m$ are given).\n",
    "- $P(\\mathbf{z}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)$ is the **Normalization term** and is a sum of product of the observation and the motion model ober the states $\\mathbf{x}_t$.\n",
    "\n",
    "To simplify the expression, we define $\\eta$ as: \n",
    "\n",
    "$$\n",
    "    \\eta = \\frac{1}{P(\\mathbf{z}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)}\n",
    "$$\n",
    "\n",
    "So we obtain:\n",
    "\n",
    "$$\n",
    "     bel(\\mathbf{x}_t) = \\eta \\times\n",
    "                        P(\\mathbf{z}_t |  \\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) \\times \n",
    "                        P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Law of Total Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To further define $\\eta$ we can use the **Law of total probality** that states that:\n",
    "\n",
    "$$\n",
    "P(B) = \\sum_{i=1}^{\\infty}P(B|A_i)P(A_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int P(B|A_i)P(A_i)\n",
    "$$\n",
    "\n",
    "This way we can further define $\\eta$ as:\n",
    "\n",
    "$$\n",
    "\\eta = \n",
    "\\frac{1}{P(\\mathbf{z}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)} =\n",
    "\\frac{1}{\n",
    "            \\sum_{i}\n",
    "                P(\\mathbf{z}_t | x_t^{(i)},\\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) \\times\n",
    "                P(x_t^{(i)}|\\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)\n",
    "        }\n",
    "$$\n",
    "\n",
    "Where:\n",
    " - $P(\\mathbf{z}_t | x_t^{(i)},\\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)$ is the **observation model** over all possible states $x_t^{(i)}$ (positions at time $t$)\n",
    " - $P(x_t^{(i)}|\\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)$ is the **motion model** over all possible states $x_t^{(i)}$ (positions at time $t$)\n",
    "\n",
    "This means that we just need to define the **motion model** and **observation model** to solve our localization problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Localization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several algorithms leverage foundational probabilistic rules to solve the localization problem. A widely used approach in robotics is Markov Localization, which effectively handles the uncertainties inherent in real-world environments.\n",
    "\n",
    "Markov Localization, is a versatile algorithm that uses a form of the Bayes' filter to estimate the position of a robot or vehicle within a known map. It integrates sensory information and movement commands over time to update the belief about the robot's location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Assumption\n",
    "\n",
    "Markov Localization comes from using the bayes filter and applying the Markov Assumption to define the **motion** and **observation** model. This assumption states thet the probability distribution of future states is dependent only upon the current state and not othe preeding states. This can be expressed as: \n",
    "\n",
    "$$\n",
    "    P(x_t | x_{t-1}, x_{t-2}, \\cdots, x_0) = P(x_t | x_{t-1})\n",
    "$$\n",
    "\n",
    "**Python Example**\n",
    "\n",
    "A simple example illustrating the Markov assumption in a robotics context involves simulating a robot's movements in a grid-like environment. Let's create a scenario where a robot can move in a deterministic environment with a limited set of actions: move forward, turn left, or turn right. We'll assume the state of the robot is defined only by its current position and orientation, and the future state is dependent solely on its current state and the action taken, which is a key aspect of the Markov assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition function for the robot\n",
    "def transition(state, action):\n",
    "    row, col, orientation = state\n",
    "    idx = orientations.index(orientation)\n",
    "    \n",
    "    if action == 'move forward':\n",
    "        if orientation == 'up' and row > 0:\n",
    "            return (row - 1, col, orientation)\n",
    "        elif orientation == 'right' and col < grid_size[1] - 1:\n",
    "            return (row, col + 1, orientation)\n",
    "        elif orientation == 'down' and row < grid_size[0] - 1:\n",
    "            return (row + 1, col, orientation)\n",
    "        elif orientation == 'left' and col > 0:\n",
    "            return (row, col - 1, orientation)\n",
    "        else:\n",
    "            return state  # No movement if it leads out of bounds\n",
    "    elif action == 'turn left':\n",
    "        new_idx = (idx - 1) % 4\n",
    "        return (row, col, orientations[new_idx])\n",
    "    elif action == 'turn right':\n",
    "        new_idx = (idx + 1) % 4\n",
    "        return (row, col, orientations[new_idx])\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Simulate the robot's movement\n",
    "def simulate_robot(steps):\n",
    "    current_state = start_state\n",
    "    path = [current_state]\n",
    "    for _ in range(steps):\n",
    "        action = np.random.choice(actions)\n",
    "        current_state = transition(current_state, action)\n",
    "        path.append(current_state)\n",
    "    return path\n",
    "\n",
    "\n",
    "grid_size = (5, 5)\n",
    "\n",
    "# Possible orientations for the robot: up, right, down, left (clockwise)\n",
    "orientations = ['up', 'right', 'down', 'left']\n",
    "\n",
    "# Actions the robot can take\n",
    "actions = ['move forward', 'turn left', 'turn right']\n",
    "\n",
    "# Start state (row, column, orientation)\n",
    "start_state = (2, 2, 'up')  # Middle of the grid, facing up\n",
    "\n",
    "\n",
    "# Simulate robot's movement for 10 steps\n",
    "robot_path = simulate_robot(10)\n",
    "print(f\"Step\\t\\tPosition\\tOrientation\")\n",
    "for t, step in enumerate(robot_path):\n",
    "    print(f\"{t}\\t\\t({step[0]}, {step[1]})\\t\\t{step[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of the Localization\n",
    "\n",
    "The initialization phase is crucial as it sets the starting point for the localization process. It begins with establishing a **prior** belief ($P(\\text{Location})$) about the vehicle's location, which significantly influences the convergence of most localization algorithms.\n",
    "\n",
    "#### Initialize Priors in a 1D environment\n",
    "\n",
    "To illustrate the initialization of priors in a Bayes Filter for localization, consider a simplified scenario:\n",
    "\n",
    "Suppose we have a 1D map that extends from 0 to 25 meters, with landmarks located at $x=5.0$, $x=10.0$, and $x=20.0$ meters. We assume a position standard deviation ($\\sigma_x$) of $1.0$ meter. If we know our vehicle is initially positioned at one of these landmarks, we should set up our initial belief state accordingly.\n",
    "\n",
    "Given the precision of $±1.0$ meters around each landmark, we can establish the probability of the vehicle being at a location next to a landmark as follows:\n",
    "\n",
    "- Positions within $[4,6]$, $[9,11]$, or $[19,21]$ meters are considered plausible initial locations for the vehicle.\n",
    "- The probability assigned to these positions is 1.0, while the probability for all other positions is set to 0.\n",
    "\n",
    "To normalize these probabilities to ensure they sum up to 1.0 across the map, we calculate the total number of positions that could potentially be occupied, which in this case is 9 (3 positions per landmark). Therefore, each of the plausible positions has a normalized probability of $1.09 \\approx 0.111$. Thus, our initial belief state is set as follows:\n",
    "\n",
    "| Position | Belief |\n",
    "|----------|--------|\n",
    "| 0        | 0.0    |\n",
    "| 1        | 0.0    |\n",
    "| 2        | 0.0    |\n",
    "| 3        | 0.0    |\n",
    "| 4        | 0.111  |\n",
    "| 5        | 0.111  |\n",
    "| 6        | 0.111  |\n",
    "| 7        | 0.0    |\n",
    "| 8        | 0.0    |\n",
    "| 9        | 0.111  |\n",
    "| 10       | 0.111  |\n",
    "| 11       | 0.111  |\n",
    "| 12       | 0.0    |\n",
    "| 13       | 0.0    |\n",
    "| 14       | 0.0    |\n",
    "| 15       | 0.0    |\n",
    "| 16       | 0.0    |\n",
    "| 17       | 0.0    |\n",
    "| 18       | 0.0    |\n",
    "| 19       | 0.111  |\n",
    "| 20       | 0.111  |\n",
    "| 21       | 0.111  |\n",
    "| 22       | 0.0    |\n",
    "| 23       | 0.0    |\n",
    "| 24       | 0.0    |\n",
    "| 25       | 0.0    |\n",
    "\n",
    "##### Python example\n",
    "\n",
    "Let's implement the Python function <code>initialize_priors_1d</code>, to set up the initial beliefs about vehicle location on a 1D map. This function considers the positions of landmarks, the standard deviation of location beliefs, the total map size, and the discretization interval of the map, $\\Delta x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%matplotlib inline\n",
    "\n",
    "def print_beliefs(beliefs:np.array, map_size: float)->None:\n",
    "    \"\"\"\n",
    "    Function to format print our beliefs\n",
    "\n",
    "    Args:\n",
    "        beliefs (np.array): beliefs to be printed\n",
    "    \"\"\"\n",
    "    print(\"position\\tbelief\")\n",
    "    num_points = (len(beliefs)-1)\n",
    "    delta_x = map_size/num_points\n",
    "    for position, belief in enumerate(beliefs):\n",
    "        print(f\"{position*delta_x:.2f} m\\t\\t{belief[0]:.3f}\")\n",
    "\n",
    "\n",
    "def initialize_priors_1d(map_size:float, landmark_positions:np.array, position_stdev:float, delta_x:float=1.0)->np.array:\n",
    "    \"\"\"\n",
    "    Function to initialize the beliefs that the car is in a given position on the map, considering map discretization.\n",
    "\n",
    "    Args:\n",
    "        map_size (int): Size of the map in meters.\n",
    "        landmark_positions (np.array): Positions on the map where landmarks are located, in meters.\n",
    "        position_stdev (float): Standard deviation of the position, defining the uncertainty around the landmarks.\n",
    "        delta_x (float): Discretization term for the map, representing the interval between points.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array with the initialized belief of the car being in a given position.\n",
    "    \"\"\"\n",
    "    # Calculate the number of discrete points on the map\n",
    "    num_points = int(map_size / delta_x) + 1  # +1 to include the zero index\n",
    "\n",
    "    # Intialize the prior belief state with zeros\n",
    "    priors = np.zeros((num_points,1))\n",
    "\n",
    "    # Convert landmark positions to discrete indices\n",
    "    discrete_landmarks = (landmark_positions / delta_x).astype(int)\n",
    "    \n",
    "    # Calculate indices around each landmark within the position standard deviation\n",
    "    for landmark in discrete_landmarks:\n",
    "        # Generate index offsets\n",
    "        indices = np.arange(landmark - position_stdev, landmark + position_stdev + 1)\n",
    "        # Ensure indices are within map boundaries\n",
    "        valid_indices = indices[(indices >= 0) & (indices < num_points)]\n",
    "        # Update priors array\n",
    "        priors[valid_indices] += 1\n",
    "\n",
    "    # Normalize the priors array\n",
    "    priors /= np.sum(priors)\n",
    "\n",
    "    return priors\n",
    "\n",
    "\n",
    "# Define map parameters\n",
    "map_size = 25  # map size in meters\n",
    "delta_x = 0.5  # discretization interval in meters\n",
    "landmarks_positions = np.array([5, 10, 20])  # landmark positions in meters\n",
    "position_stdev = 2  # position standard deviation in terms of discrete steps\n",
    "\n",
    "# Get our priors belief\n",
    "priors = initialize_priors_1d(map_size, landmarks_positions, position_stdev, delta_x)\n",
    "\n",
    "# Plotting the belief state\n",
    "xs = np.arange(0,len(priors))*delta_x\n",
    "ys = priors.flatten()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(xs,ys)\n",
    "plt.title('Initial Belief of Vehicles Location')\n",
    "plt.xlabel('Position (meters)')\n",
    "plt.ylabel('Probability')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python example with 2D Initialization\n",
    "\n",
    "For the 2D map scenario, let’s extend our method with the <code>initialize_priors_2d function</code>. This function configures the initial belief state for an autonomous vehicle navigating a 2D space. It assigns probabilities based on the proximity to known landmarks, factoring in a specified standard deviation for positional uncertainty around each landmark. Similar to the 1D version, the map is divided into discrete segments according to a given discretization scale, $\\Delta_{xy}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy\n",
    "\n",
    "def initialize_priors_2d(map_size: tuple, landmark_positions: np.array, position_stdev: float, delta_m: float=1.0) -> np.array:\n",
    "    \"\"\"\n",
    "    Initialize the prior beliefs about the vehicle's position on a 2D map, considering the discretization of the map.\n",
    "\n",
    "    Args:\n",
    "        map_size (tuple): Size of the map in meters (width, height).\n",
    "        landmark_positions (np.array): Array of landmark positions on the map [(x1, y1), (x2, y2), ...].\n",
    "        position_stdev (float): Standard deviation around each landmark, defining the uncertainty.\n",
    "        delta_ms (float): The distance between discrete positions in the map..\n",
    "\n",
    "    Returns:\n",
    "        np.array: 2D array with initialized beliefs of the vehicle being at various positions.\n",
    "    \"\"\"\n",
    "    # Calculate the number of discrete points along each dimension\n",
    "    num_points_x = int(map_size[0] / delta_m) + 1\n",
    "    num_points_y = int(map_size[1] / delta_m) + 1\n",
    "\n",
    "    # Initialize the prior belief state with zeros\n",
    "    priors = np.zeros((num_points_x, num_points_y))\n",
    "\n",
    "    # Create meshgrid for indices\n",
    "    xs, ys = np.meshgrid(np.arange(num_points_x), np.arange(num_points_y), indexing='ij')\n",
    "    \n",
    "    # Convert to xs and ys to map positions\n",
    "    xs = xs*delta_m\n",
    "    ys = ys*delta_m\n",
    "    \n",
    "    # Update the priors for each landmark\n",
    "    for (landmark_x, landmark_y) in landmark_positions:\n",
    "        # Calculate distances from each grid point to the landmark\n",
    "        distance = np.sqrt((xs - landmark_x)**2 + (ys - landmark_y)**2)\n",
    "        # Set to 1 in each posible location of our vehicle\n",
    "        priors[distance<=position_stdev] = 1.0\n",
    "\n",
    "    # Normalize the priors to sum to one\n",
    "    priors /= np.sum(priors)\n",
    "\n",
    "    return priors\n",
    "\n",
    "# Define parameters for the 2D map\n",
    "map_size = (25, 25)  # size in meters (width, height)\n",
    "delta_m = 0.2  # The distance between discrete positions in the map.\n",
    "landmark_positions = np.array([[2, 2], [10, 10], [25, 15]])  # landmark positions in meters\n",
    "position_stdev = 1.5  # standard deviation\n",
    "\n",
    "# Initialize the priors\n",
    "priors = initialize_priors_2d(map_size, landmark_positions, position_stdev, delta_m)\n",
    "\n",
    "# Plotting the belief state\n",
    "extent = [0, map_size[0], 0, map_size[1]]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(priors.T, origin='lower', extent=extent)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Initial 2D Belief of Vehicles Location')\n",
    "plt.xlabel('Position X (meters)')\n",
    "plt.ylabel('Position Y (meters)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Motion Model\n",
    "\n",
    "The Markov Localization algorithm employs Bayes' rule to estimate the position of a robot within a specific environment. This probabilistic approach relies fundamentally on two components: the **motion model** and the **observation model**. The motion model is designed to predict the vehicle's state, $\\mathbf{x}_t$, at any given time $t$, using its prior state, the actions undertaken ($\\mathbf{u}_{t:1}$), and previously observed data ($\\mathbf{z}_{t−1:1}$), within the framework of a known map $m$.\n",
    "\n",
    "Incorporating the Markov assumption to simplify our model, and applying the law of total probability, we derive the following expression:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = \\int P(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) P(\\mathbf{x}_{t-1}|  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) d\\mathbf{x}_{t-1}\n",
    "$$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "- $P(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)$ is the **state transition** probability, which models the probability of moving to state $x_t$ from state $x_{t−1}$​ given the action $u_t$​ and the map $m$. \n",
    "    \n",
    "- $P(\\mathbf{x}_{t-1}|  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)$ is the **recursive Bayesian update**, reflecting the posterior probability of the robot's state at time $t−1$ after considering all previous sensor observations and actions up to $t−1$.\n",
    "\n",
    "\n",
    "Regarding the localization problem, we can levarage on the properties of the motion model and its dependency on previous states to formulate the following assumptions:\n",
    "\n",
    "1. Since we (hypothetically) know the state of the system at timestep $t-1$, the past observations $\\mathbf{z}_{t-1:1}$ and controls $\\mathbf{u}_{t:1}$ up to $t-1$ would not provide additional information to estimate the posterior $x_t$, as they were already used to estimate $\\mathbf{x}_{t-1}$. This means, we can simplify the model as: \n",
    "\n",
    "    $$\n",
    "    P(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = P(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{u}_{t}, m)\n",
    "    $$\n",
    "\n",
    "2. Since $u_t$ is \"in the future\" with reference to $x_{t-1}$, $u_t$ does not provide additional information about $x_{t-1}$. This means that we can state that:\n",
    "\n",
    "    $$\n",
    "        P(\\mathbf{x}_{t-1}|  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = P(\\mathbf{x}_{t-1}|\\mathbf{z}_{t-1}  \\mathbf{z}_{t-2:1}, \\mathbf{u}_{t-1:1}, m)\n",
    "    $$ \n",
    "\n",
    "    Notice that we separated $\\mathbf{z}_{t-1:1}$ in $\\mathbf{z}_{t}$, $\\mathbf{z}_{t-2:1}$\n",
    "\n",
    "Combining these assumptions, we can express the motion model as:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = \\int P(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{u}_{t}, m)P(\\mathbf{x}_{t-1}|\\mathbf{z}_{t-1},  \\mathbf{z}_{t-2:1}, \\mathbf{u}_{t-1:1}, m) d\\mathbf{x}_{t-1}\n",
    "$$\n",
    "\n",
    "Now remembering our priors distribution:\n",
    "\n",
    "$$\n",
    "bel(\\mathbf{x}_t ) = P(\\mathbf{x}_{t}|\\mathbf{z}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)\n",
    "$$\n",
    "\n",
    "Then for $t-1$\n",
    "$$\n",
    "bel(\\mathbf{x}_{t-1}) = P(\\mathbf{x}_{t-1}|\\mathbf{z}_{t-1},  \\mathbf{z}_{t-2:1}, \\mathbf{u}_{t-1:1}, m)\n",
    "$$\n",
    "\n",
    "Finally we can write the motion model as:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = \\int P(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{u}_{t}, m) bel(\\mathbf{x}_{t-1}) d\\mathbf{x}_{t-1}\n",
    "$$ \n",
    "\n",
    "Or for a discrete environment:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = \\sum_i^{N} P(\\mathbf{x}_t | \\mathbf{x}^{(i)}_{t-1}, \\mathbf{u}_{t}, m) bel(\\mathbf{x}^{(i)}_{t-1})\n",
    "$$ \n",
    "\n",
    "Typically the **State Transition Model**, is assumed to be map indenpendant. Under this assumption, the model is primarily concerned with the effect of control actions $u_t$​ on the state transition from $x_{t−1}$ to $x_t$​. This simplification can be formally expressed as:\n",
    "\n",
    "$$\n",
    "    P(\\mathbf{x}_t | \\mathbf{x}^{(i)}_{t-1}, \\mathbf{u}_{t}, m) = P(\\mathbf{x}_t | \\mathbf{x}^{(i)}_{t-1}, \\mathbf{u}_{t})\n",
    "$$\n",
    "\n",
    "In this example, we will assume that the distances moved by the vehicle are normally distributed, with the vehicle's movement ($u_t$​) being the mean and a standard deviation ($\\sigma_{u}$​). This forms the basis of our Transition Model:\n",
    "\n",
    "$$\n",
    "    P(\\mathbf{x}_t | \\mathbf{x}^{(i)}_{t-1}, \\mathbf{u}_{t}) \\sim \\mathcal{N}(\\mathbf{x}_t-\\mathbf{x}^{(i)}_{t-1}; \\mathbf{u}_{t}; \\sigma_{\\mathbf{u}_{t}})\n",
    "$$\n",
    "\n",
    "This representation uses a Gaussian distribution to model the probability of transitioning from a previous state $x^{(i)}_{t−1}$​ to a new state $x_t$​, given the movement of the vehicle $u_t$​. It's important to note that this is a simplification; more sophisticated models, such as the kinematic bicycle model, can provide more accurate descriptions of vehicle dynamics, especially in contexts involving turning and complex maneuvers.\n",
    "\n",
    "#### Python Implementation\n",
    "\n",
    "Let's implement this model for discrete 1D and 2D environments, demonstrating how the motion model updates our beliefs about vehicle positions based on control inputs and prior probabilities.\n",
    "\n",
    "##### 1D Example\n",
    "\n",
    "First, we define our transition model function. This function computes the Gaussian probability density, modeling the likelihood of transitioning from one state to another given a control action. This is a core component of the motion model, representing how likely it is that a vehicle will move to a new position based on the given movement command and inherent movement uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normpdf(x: np.array, mean: float, std: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Calculate the normal probability density function (Gaussian distribution).\n",
    "\n",
    "    Args:\n",
    "        x (np.array): The points at which the Gaussian is evaluated.\n",
    "        mean (float): The mean (μ) of the Gaussian distribution, representing the expected value.\n",
    "        std (float): The standard deviation (σ) of the Gaussian distribution, representing the dispersion from the mean.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The calculated Gaussian values at each point in x.\n",
    "    \"\"\"\n",
    "    return (1 / np.sqrt(2 * np.pi * std ** 2)) * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "\n",
    "def transition_model(distance: np.array, movement: float, std: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Use a Gaussian distribution to model the transition probabilities between states based on the movement and its associated uncertainty.\n",
    "\n",
    "    Args:\n",
    "        distance (np.array): An array representing the distances from the intended new position for each prior position.\n",
    "        movement (float): The intended movement which acts as the mean of the Gaussian distribution.\n",
    "        std (float): The standard deviation of the movement, representing the uncertainty associated with the control input.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Transition probabilities calculated using the Gaussian distribution.\n",
    "    \"\"\"\n",
    "    return normpdf(distance, movement, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the motion model which calculates the updated belief about the vehicle's position after applying the control input. The model sums over all potential prior positions, weighting them by how likely each transition is given the motion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_model(pseudo_position:float, movement:float, priors:np.array, delta_x:float, control_std:float)->float:\n",
    "    \"\"\"\n",
    "    Implementation of the motion model in python. As discussed in the lesson, the probability of the car being in a position given\n",
    "    a movement and priors. The probability is modeled as a Normal distribution \n",
    "    \n",
    "    N(distance from a given position and a next position, movement, cotrol_std)\n",
    "\n",
    "    Args:\n",
    "        pseudo_position (float): Position where we want to calculate the probability \n",
    "                                 of landing in this position given a movement, a prior belief and a control standard deviation\n",
    "        movement (float): Control input\n",
    "        priors (np.array): Prior beliefs of the position of the car\n",
    "        control_std (float): Control standard deviation\n",
    "\n",
    "    Returns:\n",
    "        float: the probability of landing in a pseudo position given a movement, a prior belief and a control standard deviation\n",
    "    \"\"\"\n",
    "    position_prob = 0\n",
    "    distances = pseudo_position-np.arange(len(priors))*delta_x\n",
    "    probs = transition_model(distances, movement, control_std)\n",
    "    position_prob = probs[None,:]@priors\n",
    "    return position_prob[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the map and the priors, and then use the motion model to update our belief state based on a hypothetical control input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map parameters\n",
    "map_size = 25  # map size in meters\n",
    "delta_x = 0.5  # discretization interval in meters\n",
    "landmarks_positions = np.array([5, 10, 20])  # landmark positions in meters\n",
    "position_stdev = 2  # position standard deviation in terms of discrete steps\n",
    "\n",
    "control_stdev = 1\n",
    "movement = 2\n",
    "\n",
    "# Initialize priors based on landmarks\n",
    "priors = initialize_priors_1d(map_size, landmarks_positions, position_stdev, delta_x)\n",
    "\n",
    "# Update belief state\n",
    "position_probs = np.zeros_like(priors)\n",
    "for i in range(len(priors)):\n",
    "    x = i * delta_x\n",
    "    position_probs[i] = motion_model(x, movement, priors, delta_x, control_stdev)\n",
    "\n",
    "# Plotting the belief state\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.bar(np.arange(len(priors)) * delta_x, priors.flatten(), label=\"Priors\")\n",
    "ax1.set_title('Prior Belief of Vehicle Location')\n",
    "ax1.set_xlabel('Position (meters)')\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.bar(np.arange(len(priors)) * delta_x, position_probs.flatten(), color='green')\n",
    "ax2.set_title('Posterior Belief of Vehicle Location')\n",
    "ax2.set_xlabel('Position (meters)')\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2D example\n",
    "\n",
    "For a 2D example, we extend the motion model to handle two-dimensional movements. This involves updating our belief about the vehicle's position across a grid of possible locations based on a 2D control input and the previous belief state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_model_2D(pseudo_position_x: float, pseudo_position_y: float, movement: float, priors: np.array, delta_m: float, control_std: float) -> float:\n",
    "    \"\"\"\n",
    "    Update the belief about vehicle's position in a 2D map based on prior probability and control input.\n",
    "\n",
    "    Args:\n",
    "        pseudo_position_x (float): X-coordinate to evaluate the new probability for.\n",
    "        pseudo_position_y (float): Y-coordinate to evaluate the new probability for.\n",
    "        movement (float): The control input specifying the intended movement in both dimensions.\n",
    "        priors (np.array): The prior probability distribution over positions in the 2D space.\n",
    "        delta_m (float): The distance between discrete positions in the map.\n",
    "        control_std (float): Standard deviation of the control input effect.\n",
    "\n",
    "    Returns:\n",
    "        float: Updated probability of the vehicle being at the (pseudo_position_x, pseudo_position_y).\n",
    "    \"\"\"\n",
    "    position_prob = 0\n",
    "    x_points, y_points = priors.shape\n",
    "    xs, ys = np.meshgrid(np.arange(x_points), np.arange(y_points), indexing='ij')\n",
    "    \n",
    "    xs = xs * delta_m\n",
    "    ys = ys * delta_m\n",
    "    \n",
    "    # We consider that we only move forward\n",
    "    dx = pseudo_position_x - xs\n",
    "    dy = pseudo_position_y - ys\n",
    "    distances = np.sqrt((dx)**2 + (dy)**2)\n",
    "\n",
    "    # We consider that we only move forward\n",
    "    distances[(dx<0) & (dy<0)] *= -1\n",
    "    \n",
    "    probs = transition_model(distances, movement, control_std)\n",
    "    position_prob = np.sum(probs * priors)\n",
    "    return position_prob\n",
    "\n",
    "# Initialize and update the 2D map\n",
    "map_size = (25, 25)  # size in meters (width, height)\n",
    "delta_m = 0.5  # discretization interval in meters\n",
    "landmark_positions = np.array([[5, 5], [10, 10], [20, 20]])  # landmark positions in meters\n",
    "position_stdev = 1.5  # position standard deviation in terms of discrete steps\n",
    "\n",
    "control_stdev = 1\n",
    "movement = 1  # Movement in both x and y directions\n",
    "\n",
    "# Initialize priors based on landmarks\n",
    "priors = initialize_priors_2d(map_size, landmark_positions, position_stdev, delta_m)\n",
    "\n",
    "# Update belief state for 2D\n",
    "position_probs = np.zeros_like(priors)\n",
    "x_points, y_points = position_probs.shape\n",
    "\n",
    "for i in range(x_points):\n",
    "    for j in range(y_points):\n",
    "        x = i * delta_m\n",
    "        y = j * delta_m\n",
    "        position_probs[i, j] = motion_model_2D(x, y, movement, priors, delta_m, control_stdev)\n",
    "\n",
    "# Plotting the 2D belief state\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "extent = [0, map_size[0], 0, map_size[1]]\n",
    "\n",
    "im1 = ax1.imshow(priors, origin=\"lower\", extent=extent, cmap='hot')\n",
    "ax1.set_title(\"Prior Belief of Vehicle Location\")\n",
    "ax1.grid(True)\n",
    "fig.colorbar(im1, ax=ax1, orientation='horizontal', pad=0.08)\n",
    "\n",
    "im2 = ax2.imshow(position_probs, origin='lower', extent=extent, cmap='hot')\n",
    "ax2.set_title(\"Posterior Belief of Vehicle Location\")\n",
    "ax2.grid(True)\n",
    "fig.colorbar(im2, ax=ax2, orientation='horizontal', pad=0.08)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Observation Model\n",
    "\n",
    "Let's examine the observation model defined by the probability:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{z}_t |  \\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)\n",
    "$$\n",
    "\n",
    "Applying the Markov Assumption simplifies our model considerably. Given that the control inputs $\\mathbf{u}_{t:1}$ and previous observations $\\mathbf{z}_{t-1:1}$ are utilized to estimate the current state $\\mathbf{x}_t$, we can reduce the model to:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{z}_t |  \\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = P(\\mathbf{z}_t |  \\mathbf{x}_{t}, m)\n",
    "$$\n",
    "\n",
    "Here, the model depends only on the current state $\\mathbf{x}_t$ and the map $m$. Note that $\\mathbf{z}_t$ represents an observation vector, comprising independently measured observations:\n",
    "\n",
    "$$\n",
    "    \\mathbf{z}_t = [z_t^1,\\cdots, z_t^k]\n",
    "$$\n",
    "\n",
    "Therefore, the obeservation molde can be expresed as:\n",
    "\n",
    "$$\n",
    "    P(\\mathbf{z}_t |  \\mathbf{x}_{t}, m) = P(z_t^1,\\cdots, z_t^k |  \\mathbf{x}_{t}, m) = \\prod_{i=1}^k P(z^i_t |  \\mathbf{x}_{t}, m)\n",
    "$$\n",
    "\n",
    "#### Pseudo ranges\n",
    "\n",
    "Focus on $P(z^i_t | \\mathbf{x}_{t}, m)$, which is the probability of obtaining a measurement $z^i_t$ from state $\\mathbf{x}_{t}$. This probability largely depends on the sensor used and its measurements. We implement **sensor models** or **measurement models** to predict a theoretical measurement $\\mathbf{z}^*_t$ given the state $\\mathbf{x}_{t}$. Let's consider a sensor that measures the distance to known landmarks as depicted below:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/dimatura/pypcd/assets/27258035/42f988d5-6523-4324-a779-6a31588fd61f\" width=\"40%\" height=\"auto\" >\n",
    "</p>\n",
    "\n",
    "Key assumptions for our model include:\n",
    "\n",
    "- The observation noise follows a Gaussian distribution with a standard deviation $\\sigma_{\\mathbf{z}_t} = 1m$.\n",
    "- The measurement range is between $0m$ and $100m$..\n",
    "- Measurements are taken only in the forward direction.\n",
    "- The theoretical measurement or pseudo ranges $\\mathbf{z}^*_t$ are derived from the state $\\mathbf{x}_{t}$ and the map $m$.\n",
    "\n",
    "##### Example Scenario\n",
    "\n",
    "Consider the scenario where a car is at $x=5m$, with landmarks at positions $[0, 15, 37, 45, 53, 60, 71]$ m. The theoretical pseudo ranges that the sensor should detect, considering only forward measurements, are:\n",
    "\n",
    "- No measurement ot landmark at $0m$ as we only sense in forward direction\n",
    "- $10m$ to landarmk at $15m$\n",
    "- $32m$ to landarmk at $37m$\n",
    "- $40m$ to landarmk at $45m$\n",
    "- $48m$ to landarmk at $53m$\n",
    "- $55m$ to landarmk at $60m$\n",
    "- $66m$ to landarmk at $71m$\n",
    "\n",
    "Therefore, the psuedo ranges are:\n",
    "\n",
    "$$\n",
    "    \\mathbf{z}^*_t = [10, 32, 40, 48, 55, 66] m\n",
    "$$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/Gaurang-1402/Drona/assets/27258035/f64ee37a-7037-4e7c-a191-38f023d33c7e\" width=\"40%\" height=\"auto\" >\n",
    "</p>\n",
    "\n",
    "\n",
    "#### Python Implementation\n",
    "\n",
    "Let's implement our pseudo range estimator. This function calculates pseudo ranges based on the position of the car and known landmark positions. It returns distances only for landmarks that are forward of the vehicle's position; landmarks located behind the vehicle return <code>NaN</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_range_estimator(landmark_positions:np.array, pseudo_position:float)->np.array:\n",
    "    \"\"\"\n",
    "    Function that estimates the pseudo ranges given a position. Remember that a pseudo range\n",
    "    is the distance the car would observe if its state is pseudo position. \n",
    "\n",
    "    Args:\n",
    "        landmark_positions (np.array): Positions in the map where landmarks are located\n",
    "        pseudo_position (float): Position where the car could be\n",
    "\n",
    "    Returns:\n",
    "        np.array: estimated pseudo ranges\n",
    "    \"\"\"\n",
    "    if len(landmark_positions.shape) == 1:\n",
    "        landmark_positions = landmark_positions[:, np.newaxis]\n",
    "\n",
    "    # Calculate ranges as the distances to the landmarks\n",
    "    diff = landmark_positions - pseudo_position    \n",
    "    pseudo_ranges = np.sqrt(np.sum(diff**2,axis=1))\n",
    "    \n",
    "    # apply a mask to return np.nan to backward measurements.\n",
    "    # In a 2D case backward measurmentes are mesuraments \n",
    "    # whose x and y components are negative.\n",
    "    mask = np.all(diff<0, axis=1)\n",
    "    pseudo_ranges[mask] = np.nan\n",
    "    \n",
    "    return pseudo_ranges\n",
    "\n",
    "landmarks_positions_1D = np.array([5, 10, 20])  # landmark positions in meters in one dimension\n",
    "landmarks_positions_2D = np.array([[5, 5], [10,10], [20,20]]) # landmark positions in meters in two dimensions\n",
    "\n",
    "pseudo_position_1D = 10  # x position for a 1D example\n",
    "pseudo_position_2D = np.array([[7, 2]]) # (x,y) position for a 2D example\n",
    "\n",
    "pseudo_ranges_1D = pseudo_range_estimator(landmarks_positions_1D, pseudo_position_1D)\n",
    "pseudo_ranges_2D = pseudo_range_estimator(landmarks_positions_2D, pseudo_position_2D)\n",
    "\n",
    "print(f\"Example one dimension:\")\n",
    "print(f\"Lanmarks: {landmarks_positions_1D}\")\n",
    "print(f\"Position: {pseudo_position_1D}\")\n",
    "print(f\"Pseudo ranges: {pseudo_ranges_1D}\")\n",
    "\n",
    "print(f\"Example two dimension:\")\n",
    "print(f\"Lanmarks: {landmarks_positions_2D}\")\n",
    "print(f\"Position: {pseudo_position_2D}\")\n",
    "print(f\"Pseudo ranges: {pseudo_ranges_2D}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of 2D Pseudo Ranges\n",
    "The 1D pseudo range estimator function calculates distances from a specified vehicle position to an array of landmarks positioned along a single axis. This is useful for simulations where vehicle and landmark positions are constrained to a linear path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map parameters\n",
    "map_size = 25  # map size in meters\n",
    "delta_x = 0.5  # discretization interval in meters\n",
    "landmarks_positions = np.array([5, 10, 20])  # landmark positions in meters\n",
    "position_stdev = 2  # position standard deviation in terms of discrete steps\n",
    "\n",
    "# Generate positions and compute pseudo ranges for each position\n",
    "positions = np.linspace(0, map_size, int(map_size / delta_x) + 1)\n",
    "pseudo_ranges_list = [pseudo_range_estimator(landmarks_positions, x) for x in positions]\n",
    "\n",
    "# Prepare the updated scatter plot with simplified legend entries\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Color mapping for each unique landmark position\n",
    "unique_landmarks = np.unique(landmarks_positions)\n",
    "colors = ['blue', 'green', 'orange']\n",
    "landmark_color_map = {landmark: color for landmark, color in zip(unique_landmarks, colors)}\n",
    "\n",
    "# Track which labels have been added to the legend\n",
    "legend_labels_added = set()\n",
    "\n",
    "# Plot scatter data with consistent color mapping for landmarks\n",
    "fig = plt.figure()\n",
    "for idx, x in enumerate(positions):\n",
    "    pseudo_ranges = pseudo_ranges_list[idx]\n",
    "    for pseudo_range in pseudo_ranges:\n",
    "        if np.isnan(pseudo_range):\n",
    "            continue\n",
    "\n",
    "        landmark_position = x + pseudo_range\n",
    "        color = landmark_color_map[landmark_position]\n",
    "        label = f'Landmark at {landmark_position}m' if color not in legend_labels_added else None\n",
    "        plt.scatter(x, pseudo_range, color=color, alpha=0.6, label=label)\n",
    "        if label:\n",
    "            legend_labels_added.add(color)\n",
    "\n",
    "plt.title('Pseudo Ranges for Each Position and Landmark')\n",
    "plt.xlabel('Position (m)')\n",
    "plt.ylabel('Pseudo Range (m)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of 2D Pseudo Ranges\n",
    "Visualizing 2D pseudo ranges offers a more comprehensive view of the sensor's capabilities and limitations in a planar environment. We use heatmaps to represent the distance from each grid point to nearby landmarks, highlighting variations in sensor reach and obstacles' influence on sensed distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and update the 2D map\n",
    "map_size = (25, 25)  # size in meters (width, height)\n",
    "delta_m = 0.5  # discretization interval in meters\n",
    "landmark_positions = np.array([[5, 5], [10,10], [20,20]])  # landmark positions in meters\n",
    "position_stdev = 1.5  # position standard deviation in terms of discrete steps\n",
    "\n",
    "\n",
    "# Define a grid\n",
    "num_x_points = int(map_size[0] / delta_m) + 1\n",
    "num_y_points = int(map_size[1] / delta_m) + 1\n",
    "\n",
    "xs = np.linspace(0, map_size[0], num_x_points)\n",
    "ys = np.linspace(0, map_size[1], num_y_points)\n",
    "\n",
    "xs, ys = np.meshgrid(xs, ys, indexing='ij')\n",
    "\n",
    "# Initialize an array to store the minimum pseudo ranges\n",
    "pseudo_ranges = np.zeros((num_x_points, num_y_points, len(landmark_positions)))\n",
    "\n",
    "# Calculate the minimum pseudo range for each point on the grid\n",
    "for i in range(num_x_points):\n",
    "    for j in range(num_y_points):\n",
    "        pseudo_position = (xs[i, j], ys[i, j])\n",
    "        pseudo_ranges[i, j,:] = pseudo_range_estimator(landmark_positions, pseudo_position)\n",
    "\n",
    "# Plot Psudo ranges\n",
    "# Initialize the figure for subplots based on the number of landmarks\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(landmark_positions), figsize=(18, 5), sharey=True)\n",
    "\n",
    "# Calculate and plot a heatmap for each landmark\n",
    "for idx, (landmark, ax) in enumerate(zip(landmark_positions, axes.flatten())):\n",
    "\n",
    "    # Compute the distances from this landmark to each point on the grid\n",
    "    distances = pseudo_ranges[:,:,idx]\n",
    "    \n",
    "    # Plotting the heatmap\n",
    "    c = ax.imshow(distances, extent=[0, map_size[0], 0, map_size[1]], origin='lower', cmap='viridis', interpolation='nearest')\n",
    "    ax.scatter(landmark[0], landmark[1], color='red', s=100, label=f'Landmark {idx+1}')\n",
    "    ax.set_title(f'Heatmap for Landmark {idx+1}')\n",
    "    ax.set_xlabel('X coordinate')\n",
    "    if idx == 0:  # Only add y label to the first subplot to avoid clutter\n",
    "        ax.set_ylabel('Y coordinate')\n",
    "    ax.legend()\n",
    "    fig.colorbar(c, ax=ax, orientation='horizontal', pad=0.12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the range estimator does not provide measurements for landmarks once they are positioned behind the vehicle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the Observation model\n",
    "\n",
    "To implement the observation model, we utilize the pseudo ranges. Given that the observation noise follows a Gaussian distribution with a standard deviation of $\\sigma_{\\mathbf{z}_t}$, we can estimate the measurement model distribution as follows:\n",
    "\n",
    "$$P(z^i_t |  \\mathbf{x}_{t}, m) \\sim \\mathcal{N}(z^i_t,z^{*^i}_t, \\sigma_{\\mathbf{z}_t})$$\n",
    "\n",
    "Consequently, the observation model distribution is represented by the product of individual Gaussian distributions:\n",
    "\n",
    "$$\n",
    "    P(\\mathbf{z}_t |  \\mathbf{x}_{t}, m)  = \\prod_{i=1}^k P(z^i_t |  \\mathbf{x}_{t}, m) \\sim \\prod_{i=1}^k \\mathcal{N}(z^i_t,z^{*^i}_t, \\sigma_{\\mathbf{z}_t})\n",
    "$$\n",
    "\n",
    "\n",
    "At each time step, the observation model performs the following steps for a given pseudo position:\n",
    "\n",
    "1. Measure the range to landmarks within the map boundaries in the forward direction of the vehicle.\n",
    "2. Calculate the pseudo range estimate for each landmark by subtracting the pseudo position from the landmark position.\n",
    "3. Match each pseudo range estimate with its closest observation measurement.\n",
    "4. For each pair of pseudo range estimate and observation measurement, calculate the probability using the distribution $\\mathcal{N}(z^i_t, z^{*^i}t, \\sigma{\\mathbf{z}_t})$.\n",
    "5. Compute the product of all probabilities to form the overall observation model distribution: $$\\prod_{i=1}^k \\mathcal{N}(z^i_t, z^{*^i}_t, \\sigma_{\\mathbf{z}_t})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python Implementation of the observation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_model(observations:np.array, pseudo_ranges:np.array, observation_stdev:float)->float:\n",
    "    \"\"\"\n",
    "    Implementation of the observation model. The observation model is the probability of having an observation given\n",
    "    that we are in a given position that yields the pseudo ranges.\n",
    "\n",
    "    Args:\n",
    "        observations (np.array): Observations obtained by our sensor\n",
    "        pseudo_ranges (np.array): Pseudo ranges obtained in a given pseudo position\n",
    "        observation_stdev (float): Standard deviation of the noise of our sensor\n",
    "\n",
    "    Returns:\n",
    "        (float): Calculated probability\n",
    "    \"\"\"\n",
    "    \n",
    "    distance_prob = 1\n",
    "    \n",
    "    for idx, observation in enumerate(observations):\n",
    "        pseudo_range_min = 0\n",
    "        if idx < len(pseudo_ranges):\n",
    "            pseudo_range_min = pseudo_ranges[idx]\n",
    "        else:\n",
    "            pseudo_range_min = np.inf\n",
    "\n",
    "        distance_prob = distance_prob*normpdf(observation, pseudo_range_min, observation_stdev)\n",
    "\n",
    "    return distance_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the observation model in one dimension\n",
    "\n",
    "Let's visualize the probability distribution of the observation model when we meausure. Look how is the distribuition over all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map parameters\n",
    "map_size = 25  # map size in meters\n",
    "delta_x = 0.5  # discretization interval in meters\n",
    "landmarks_positions = np.array([5, 10, 20])  # landmark positions in meters \n",
    "\n",
    "# Generate psuedo positions\n",
    "positions = np.linspace(0, map_size, int(map_size / delta_x) + 1)\n",
    "\n",
    "# Placeholder to plot the observation model at each pseudo positon\n",
    "observation_probs = np.zeros_like(positions)\n",
    "\n",
    "# Step 1. Measure the ranges to landmarks \n",
    "sensor_obs = np.asarray([2,8,18])\n",
    "observation_std = 1.5\n",
    "\n",
    "for idx, x in enumerate(positions):\n",
    "    # Step 2. Calculate pseudo ranges\n",
    "    pseudo_ranges = pseudo_range_estimator(landmarks_positions, x)\n",
    "    \n",
    "    # Step 3. Match pseudo ranges, in this case the observations are sorted\n",
    "    # and as the pseudo ranges doesnt calculate the range to landmarks in \n",
    "    # the back, we just need to sort the pseudo ranges and filter the np.nan values\n",
    "    # then the idx of a psuedo range will match with a measurement\n",
    "    pseudo_ranges = np.sort(pseudo_ranges[~np.isnan(pseudo_ranges)])\n",
    "\n",
    "    # Step 4 and 5.\n",
    "    observation_probs[idx] = observation_model(sensor_obs, pseudo_ranges, observation_std)\n",
    "\n",
    "# Plots\n",
    "plt.figure()\n",
    "\n",
    "# Plot landmarks\n",
    "plt.vlines(sensor_obs, ymin=0, ymax=np.max(observation_probs), color='black', linestyles='--', label='Landmarks')\n",
    "\n",
    "# Plotting the belief state\n",
    "plt.bar(positions, observation_probs.flatten(), color='green', label=\"Observation model\")\n",
    "plt.title('Probability of getting the observations given a position')\n",
    "plt.xlabel('Position (meters)')\n",
    "plt.ylabel('Probability')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the observation model in two dimensions.\n",
    "\n",
    "Now let's visualize the observation model in a two dimension space using heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map parameters\n",
    "map_size = (25, 25)  # size in meters (width, height)\n",
    "delta_m = 0.5  # discretization interval in meters\n",
    "landmark_positions = np.array([[5, 5], [10,10], [20,20]])  # landmark positions in meters\n",
    "position_stdev = 1.5  # position standard deviation in terms of discrete steps\n",
    "\n",
    "# Measurements\n",
    "sensor_obs = np.array([4.84, 18.067])\n",
    "observation_stdev = 1.0\n",
    "\n",
    "# Define a grid\n",
    "num_x_points = int(map_size[0] / delta_m) + 1\n",
    "num_y_points = int(map_size[1] / delta_m) + 1\n",
    "\n",
    "# Generate pseudo position in 2D\n",
    "xs = np.linspace(0, map_size[0], num_x_points)\n",
    "ys = np.linspace(0, map_size[1], num_y_points)\n",
    "xs, ys = np.meshgrid(xs, ys, indexing='ij')\n",
    "\n",
    "# Placeholder to plot the observation model at each pseudo positon\n",
    "observation_probs = np.zeros((num_x_points, num_y_points))\n",
    "\n",
    "# Calculate the minimum pseudo range for each point on the grid\n",
    "for i in range(num_x_points):\n",
    "    for j in range(num_y_points):\n",
    "        pseudo_position = (xs[i, j], ys[i, j])\n",
    "        pseudo_ranges = pseudo_range_estimator(landmark_positions, pseudo_position)\n",
    "        pseudo_ranges = np.sort(pseudo_ranges[~np.isnan(pseudo_ranges)])\n",
    "        \n",
    "        observation_probs[i,j] = observation_model(sensor_obs, pseudo_ranges, observation_stdev)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(observation_probs, origin=\"lower\", extent=[0, map_size[0], 0, map_size[1]], cmap='viridis')\n",
    "plt.scatter(landmark_positions[:, 0], landmark_positions[:, 1], color='red', marker='x', s=100, label='Landmarks')\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title(\"Observation model of Vehicle Location\")\n",
    "plt.xlabel(\"X Position (m)\")\n",
    "plt.ylabel(\"Y Position (m)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration of Models\n",
    "\n",
    "Now equipped with a clear understanding of how to derive and calculate both the motion model and observation model, we can effectively solve the localization problem. The belief in the state at time $t$ can be computed as follows:\n",
    "\n",
    "$$\n",
    "bel(\\mathbf{x}_t) = \n",
    "     \\eta \\times P(\\mathbf{z}_t |  \\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) \\times P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m)\n",
    "$$\n",
    "\n",
    "With the simplifications previously established:\n",
    "\n",
    "- **Motion model:**\n",
    "\n",
    "$$\n",
    "     P(\\mathbf{x}_t | \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = \\sum_i^{N} P(\\mathbf{x}_t | \\mathbf{x}^{(i)}_{t-1}, \\mathbf{u}_{t}, m) bel(\\mathbf{x}^{(i)}_{t-1})\n",
    "$$\n",
    "\n",
    "- **Observation Modle:**\n",
    "\n",
    "$$\n",
    "     P(\\mathbf{z}_t |  \\mathbf{x}_{t},  \\mathbf{z}_{t-1:1}, \\mathbf{u}_{t:1}, m) = \\prod_{i=1}^k P(z^i_t |  \\mathbf{x}_{t}, m)\n",
    "$$\n",
    "\n",
    "Where $\\eta$ serves as a normalization constant, calculated as the inverse of the sum of the observation model and motion model probabilities across all states.\n",
    "\n",
    "Finally the Localization algorithm can formulated as:\n",
    "\n",
    "1. **Initialization:** Initialize the prior belief about the vehicle's location, assuming proximity to a landmark with known uncertainty.\n",
    "\n",
    "For each posible state:\n",
    "\n",
    "2. **Predict the position of the vehicle** Calculate the probability of the position of the vehicle using motion model and previous belief. \n",
    "\n",
    "3. **Observe the position of the vehicle** Generate a pseudo-measurement for the current possible state, and use the observation model to estimate the probability distribution of the vehicle's position given the measurements.\n",
    "\n",
    "4. **Correct the position of the vehicle** Multiply the motion probability and observation probability for that state to derive the unnormalized probability of the vehicle's location.\n",
    "\n",
    "5. **Repeat** Repeat **2** until you have calculated all unnormalized probablitities for all possible states.\n",
    "\n",
    "6. **Normalization** Normalize the probabilities for each state by dividing by the sum of all state probabilities.\n",
    "\n",
    "7. **Update prior belief** Assing the prior belief to your current belief and go to 2. for the next timestep. \n",
    "\n",
    "#### Python implementation\n",
    "\n",
    "Let's implement the complete localization algorithm, processing several measurements across different timesteps. At each timestep and for each measurement, we compute both the motion model and observation model for all possible states, continuously updating our belief regarding the vehicle's location.\n",
    "\n",
    "##### One dimensional example\n",
    "\n",
    "In this one-dimensional example, we'll focus on a simplified scenario where both vehicle and landmarks are positioned along a single axis. This simplification allows us to clearly illustrate the algorithm's mechanics without the complexity of multi-dimensional space, making the conceptual details more accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.utils as utils\n",
    "\n",
    "# Define map parameters\n",
    "map_size = 25  # map size in meters\n",
    "delta_x = 0.5  # discretization interval in meters\n",
    "landmarks_positions = np.array([3, 9, 14, 23])  # landmark positions in meters\n",
    "position_stdev = 2  # position standard deviation in terms of discrete steps\n",
    "\n",
    "movement = 1\n",
    "control_stdev = 1\n",
    "\n",
    "sensor_obs = [np.asarray([1,7,12,21]), \n",
    "              np.asarray([0,6,11,20]), \n",
    "              np.asarray([5,10,19]),\n",
    "              np.asarray([4,9,18]), \n",
    "              np.asarray([3,8,17]), \n",
    "              np.asarray([2,7,16]), \n",
    "              np.asarray([1,6,15]),\n",
    "              np.asarray([0,5,14]), \n",
    "              np.asarray([4,13]), \n",
    "              np.asarray([3,12]), \n",
    "              np.asarray([2,11]), \n",
    "              np.asarray([1,10]),\n",
    "              np.asarray([0,9]), \n",
    "              np.asarray([8]), \n",
    "              np.asarray([7]), \n",
    "              np.asarray([6]), \n",
    "              np.asarray([5]), \n",
    "              np.asarray([4]), \n",
    "              np.asarray([3]), \n",
    "              np.asarray([2]),\n",
    "              np.asarray([1]), \n",
    "              np.asarray([0]), \n",
    "              np.asarray([]), \n",
    "              np.asarray([]), \n",
    "              np.asarray([])]\n",
    "\n",
    "observation_stdev = 1\n",
    "distance_max = 25\n",
    "\n",
    "# Initialize map positions\n",
    "xs = np.linspace(0, map_size, int(map_size / delta_x) + 1)\n",
    "\n",
    "# Initialize priors based on landmarks\n",
    "priors = initialize_priors_1d(map_size, landmarks_positions, position_stdev, delta_x)\n",
    "\n",
    "# Posteriors\n",
    "\n",
    "posteriors_list = [priors.flatten()]\n",
    "\n",
    "for t, observations in enumerate(sensor_obs):\n",
    "    \n",
    "    posteriors = np.zeros_like(priors)\n",
    "\n",
    "    # step through each pseudo position x (i)\n",
    "    for idx, pseudo_position in enumerate(xs):\n",
    "\n",
    "        # Calculate the motion model probability for each x position\n",
    "        motion_prob = motion_model(pseudo_position, movement, priors, delta_x, control_stdev)\n",
    "        # Calculate the pseudo ranges\n",
    "        pseudo_ranges = pseudo_range_estimator(landmarks_positions, pseudo_position)\n",
    "        pseudo_ranges = np.sort(pseudo_ranges[~np.isnan(pseudo_ranges)])\n",
    "        # Get the observation probability\n",
    "        observation_prob = observation_model(observations, pseudo_ranges, observation_stdev)\n",
    "        posteriors[idx, 0] = motion_prob*observation_prob\n",
    "    posteriors = posteriors/np.sum(posteriors)\n",
    "\n",
    "    posteriors_list.append(posteriors)\n",
    "    priors = posteriors.copy()\n",
    "\n",
    "utils.animate_markov_loc_results_1D(posteriors_list,xs,[0, 25], [0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Two dimensional example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this two-dimensional example, we explore a scenario where the vehicle and landmarks are distributed over a planar area. This setup reflects more realistic conditions as vehicles generally navigate through environments that require understanding both horizontal and vertical spatial relationships. In the 2D model, both the vehicle's movement and the landmarks' positions are considered along two axes (X and Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and update the 2D map\n",
    "map_size = (25, 25)  # size in meters (width, height)\n",
    "delta_m = 0.5  # discretization interval in meters\n",
    "landmarks_positions = np.array([[5, 5], [10, 10], [20, 20]])  # landmark positions in meters\n",
    "position_stdev = 1.5  # position standard deviation in terms of discrete steps\n",
    "\n",
    "control_stdev = 1\n",
    "movement = 1  # Movement in both x and y directions\n",
    "\n",
    "\n",
    "sensor_obs = [[ 1.733, 8.742, 22.811],\n",
    "              [ 0.811, 6.913, 23.203],\n",
    "              [ 2.104, 7.419, 20.595],\n",
    "              [ 2.341, 5.648, 19.796],\n",
    "              [ 3.880, 17.859],\n",
    "              [ 2.892, 17.450],\n",
    "              [ 0.849, 16.421],\n",
    "              [ 1.321, 15.108],\n",
    "              [ 2.604, 16.923],\n",
    "              [ 1.394, 15.197],\n",
    "              [ 4.041, 12.801],\n",
    "              [12.52034557],\n",
    "              [11.97141456],\n",
    "              [11.19377492],\n",
    "              [10.66756558],\n",
    "              [7.2043495  ],\n",
    "              [7.29971996 ]]\n",
    "\n",
    "observation_stdev = 1\n",
    "\n",
    "# Initialize priors based on landmarks\n",
    "priors = initialize_priors_2d(map_size, landmark_positions, position_stdev, delta_m)\n",
    "\n",
    "# Update belief state for 2D\n",
    "posteriors_list = [priors]\n",
    "\n",
    "x_points, y_points = priors.shape\n",
    "\n",
    "for t, observations in enumerate(sensor_obs):\n",
    "    posteriors = np.zeros_like(priors)\n",
    "    for i in range(x_points):\n",
    "        x = i * delta_m\n",
    "        for j in range(y_points):\n",
    "            y = j * delta_m\n",
    "\n",
    "            pseudo_position = (x,y)\n",
    "            # Calculate the motion model probability for each x position\n",
    "            motion_prob= motion_model_2D(x, y, movement, priors, delta_m, control_stdev)\n",
    "            # Calculate the pseudo ranges\n",
    "            pseudo_ranges = pseudo_range_estimator(landmarks_positions, pseudo_position)\n",
    "            pseudo_ranges = np.sort(pseudo_ranges[~np.isnan(pseudo_ranges)])\n",
    "            # Get the observation probability\n",
    "            observation_prob = observation_model(observations, pseudo_ranges, observation_stdev)\n",
    "            posteriors[i, j] = motion_prob*observation_prob\n",
    "\n",
    "    posteriors /= np.sum(posteriors)\n",
    "    priors = posteriors.copy()\n",
    "    posteriors_list.append(posteriors)\n",
    "\n",
    "utils.animate_markov_loc_results_2D(posteriors_list, [0, map_size[0]], [0, map_size[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
